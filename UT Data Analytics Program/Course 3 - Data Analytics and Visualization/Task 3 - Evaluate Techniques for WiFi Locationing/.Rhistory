trainingDataWCombinedNumeric_sample <- trainingDataWCombinedNumeric[sample(1:nrow(trainingDataWCombinedNumeric), 2500, replace=FALSE),]
#Review correlation matrix  -  are there correlations between attributes (not predicted/label attribute)
#trainingDataWCombinedNumeric_sample <- trainingDataWCombinedNumeric_sample[complete.cases(trainingDataWCombinedNumeric_sample), ]
#corrData <- cor(trainingDataWCombinedNumeric_sample[sapply(trainingDataWCombinedNumeric_sample, is.numeric)], use='pairwise')
corrData <- cor(trainingDataWCombinedNumeric_sample, use = "pairwise.complete.obs")
#corrplot(corrData)
corrData
write.csv(corrData, file = "corrData.csv")
volCorrData <- corrData[,"label_location", drop=FALSE]
write.csv(volCorrData, file = "volCorrData.csv")
#Looking for predictors highly correlated to the dependent variable volume
#where correlation greater than .95
# label_location
#nothing above .85 - no correlations, nor colinearity
#readyData_existingProductCorFRemoved <- readyData_existingProduct   # make a copy
#readyData_existingProductCorFRemoved$x5StarReviews <- NULL   # remove 5Star
#str(readyData_existingProductCorFRemoved)
#Looking for colinearity amongst predictors where correlation greater than .90
# x2StarReviews::x1StarReviews   0.951912978
# x3StarReviews::x4StarReviews   0.9372141751
#
# Remove feature with lower correlation to volume
#
# Volume::x1StarReviews   0.255023904
# Volume::x2StarReviews   0.487279328
# Remove feature: x1StarReviews
#readyData_existingProductCorFRemoved$x1StarReviews <- NULL   # remove 1Star
#str(readyData_existingProductCorFRemoved)
#
# Volume::x3StarReviews   0.763373189
# Volume::x4StarReviews   0.879006394
# Remove feature:  x3StarReviews
#readyData_existingProductCorFRemoved$x3StarReviews <- NULL   # remove 1Star
#str(readyData_existingProductCorFRemoved)
# remove obvious features (e.g., ID, other)
#WholeYear7v <- WholeYear   # make a copy
#WholeYear7v$X <- NULL   # remove ID
#str(WholeYear7v) # 35136 obs. of  7 variables
#Scale features as needed weight and height, price and volume features
#names(readyData_existingProductCorFRemoved)
#readyData_existingProductCorFRemoved[c(14, 20:24)] <- scale(readyData_existingProductCorFRemoved[c(14, 20:25)])
#summary(readyData_existingProductCorFRemoved)
# save preprocessed dataset
write.csv(trainingDataWCombinedNumeric_sample, file = "trainingDataWCombinedNumeric_sample.csv")
write.csv(trainingDataWCombinedNumeric, file = "trainingDataWCombinedNumeric.csv")
write.csv(trainingDataWCombined, file = "trainingDataWCombined.csv")
#create a smaller sample of records from the training set
trainingDataWCombinedNumeric_sample <- trainingDataWCombinedNumeric[sample(1:nrow(trainingDataWCombinedNumeric), round(nrow(WholeYear)*.1), replace=FALSE),]
#Review correlation matrix  -  are there correlations between attributes (not predicted/label attribute)
#trainingDataWCombinedNumeric_sample <- trainingDataWCombinedNumeric_sample[complete.cases(trainingDataWCombinedNumeric_sample), ]
#corrData <- cor(trainingDataWCombinedNumeric_sample[sapply(trainingDataWCombinedNumeric_sample, is.numeric)], use='pairwise')
corrData <- cor(trainingDataWCombinedNumeric_sample, use = "pairwise.complete.obs")
#corrplot(corrData)
corrData
#create a smaller sample of records from the training set
trainingDataWCombinedNumeric_sample <- trainingDataWCombinedNumeric[sample(1:nrow(trainingDataWCombinedNumeric), round(nrow(WholeYear)*.1), replace=FALSE),]
trainingDataWCombinedNumeric <- trainingDataWCombined
trainingDataWCombined = trainingData %>% unite("label_location", FLOOR:SPACEID, na.rm = TRUE, remove = FALSE)
# Clear objects if necessary
rm(list = ls())
# get working directory
wd <- getwd()
# set working directory
setwd(wd)
dir()
# set a value for seed (to be used in the set.seed function)
seed <- 123
if(!require(caret)){
install.packages("caret")
library(caret)
}
if(!require(corrplot)){
install.packages("corrplot")
library(corrplot)
}
if(!require(readr)){
install.packages("readr")
library(readr)
}
if(!require(dplyr)){
install.packages("dplyr")
library(dplyr)
}
if(!require(tidyr)){
install.packages("tidyr")
library(tidyr)
}
if(!require(doParallel)){
install.packages("doParallel")
library(doParellel)
}
detectCores()  # detect number of cores
cl <- makeCluster(5)  # select number of cores; 2 in this example
registerDoParallel(cl) # register cluster
getDoParWorkers()  # confirm number of cores being used by RStudio
# --- Load Train/Existing data (Dataset 1) --- ############
trainingData <- read.csv("trainingData.csv", stringsAsFactors = FALSE)
# Title: C3T3 Pipeline
# Last update: 01/06/2020
# File/project name: C3T3 Pipeline.R
# RStudio Project name: Task 3 - Evaluate Techniques for WiFi Locationing.Rproj
###############
# Project Notes
###############
# Now it's time to begin a new project for a new client. Our client is
# developing a system to be deployed on large industrial campuses, in
# shopping malls, et cetera to help people to navigate a complex,
# unfamiliar interior space without getting lost. While GPS works fairly
# reliably outdoors, it generally doesn't work indoors, so a different
# technology is necessary. Our client would like us to investigate the
# feasibility of using "wifi fingerprinting" to determine a person's
# location in indoor spaces. Wifi fingerprinting uses the signals from
# multiple wifi hotspots within the building to determine location,
# analogously to how GPS uses satellite signals. We have been provided
# with a large database of wifi fingerprints for a multi-building
# industrial campus with a location (building, floor, and location ID)
# associated with each fingerprint. Your job is to evaluate multiple
# machine learning models to see which produces the best result,
# enabling us to make a recommendation to the client. If your
# recommended model is sufficiently accurate, it will be incorporated
# into a smartphone app for indoor locationing.
#
# This is a deceptively difficult problem to solve. I'm looking forward
# to seeing what you come up with. After completing your analyses,
# please prepare an internal report on the project for IOT Analytics;
# because this initial report will be delivered to an internal audience,
# it can contain more technical detail than the report we will eventually
# present to the client. I have attached some sample data for you to use
# for your analysis.
# Comment multiple lines
# WIN: CMD + SHIFT + C
###############
# Housekeeping
###############
# Clear objects if necessary
rm(list = ls())
# get working directory
wd <- getwd()
# set working directory
setwd(wd)
dir()
# set a value for seed (to be used in the set.seed function)
seed <- 123
################
# Load packages
################
if(!require(caret)){
install.packages("caret")
library(caret)
}
if(!require(corrplot)){
install.packages("corrplot")
library(corrplot)
}
if(!require(readr)){
install.packages("readr")
library(readr)
}
if(!require(dplyr)){
install.packages("dplyr")
library(dplyr)
}
if(!require(tidyr)){
install.packages("tidyr")
library(tidyr)
}
if(!require(beepr)){
install.packages("beepr")
library(beepr)
}
#####################
# Parallel processing
#####################
#--- for WIN ---#
if(!require(doParallel)){
install.packages("doParallel")
library(doParellel)
}
detectCores()  # detect number of cores
cl <- makeCluster(5)  # select number of cores; 2 in this example
registerDoParallel(cl) # register cluster
getDoParWorkers()  # confirm number of cores being used by RStudio
# Stop Cluster. After performing your tasks, make sure to stop your cluster.
#stopCluster(cl)
##################
# Train/test sets
##################
#setwd("C:\\Users\\kburr\\Desktop\\UT Data Analytics Program\\Course 3 - Data Analytics and Visualization\\Task 3 - Evaluate Techniques for WiFi Locationing")
getwd()
##################
# Train/test sets
##################
setwd("C:\\Users\\kburr\\Desktop\\UT Data Analytics Program\\Course 3 - Data Analytics and Visualization\\Task 3 - Evaluate Techniques for WiFi Locationing")
getwd()
trainingDataWCombined <- read.csv("trainingDataWCombined.csv")
# create the training partition that is 75% of total obs
set.seed(seed) # set random seed
inTraining <- createDataPartition(trainingDataWCombined$label_location, p=.75, list=FALSE)
# create training/testing dataset
trainSet <- trainingDataWCombined[inTraining,]
testSet <- trainingDataWCombined[-inTraining,]
# verify number of obs
nrow(trainSet)
nrow(testSet)
nrow(trainingDataWCombined)
rfFit1 <- readRDS("rfFit1Model.rds")
knnFit1 <- readRDS("knnFit1Model.rds")
c50Fit1 <- readRDS("C50Fit1Model.rds")
# use resamples to compare model performance
ModelFitResults <- resamples(list(rf=rfFit1, knn=knnFit1, c50=c50Fit1))
# output summary metrics for tuned models
summary(ModelFitResults)
rfPred1 <- predict(rfFit1, testSet)
beep("fanfare")
# performace measurment
postResample(rfPred1, testSet$label_location)
# plot predicted verses actual
plot(rfPred1,testSet$label_location)
# print predictions
rfPred1
knnPred1 <- predict(knnFit1, testSet)
beep("fanfare")
# performace measurment
postResample(knnPred1, testSet$label_location)
# print predictions
knnPred1
# make predictions with c5.0 Model
c50Pred1 <- predict(c50Fit1, testSet)
beep("fanfare")
# performace measurment
postResample(c50Pred1, testSet$label_location)
# print predictions
c50Pred1
View(trainSet)
cmRF <-confusionMatrix(rfPred1, testSet$label_location)
cmRF
print(cmRF)
str(cmRF)
tocsv <- data.frame(cbind(t(cmRF$overall),t(cmRF$byClass)))
tocsv <- data.frame(cbind(t(cmRF$overall)))
tocsv
as.table(cmRF)
as.matrix(results,what="overall")
as.matrix(cmRF,what="overall")
as.matrix(results, what = "classes")
as.matrix(cmRF, what = "classes")
write.csv(as.table(cmRF), file = "cmRF")
write.csv(as.table(cmRF), file = "cmRF.csv")
write.csv(as.matrix(cmRF,what="overall"), file = "cmRF_overall.csv")
write.csv(as.matrix(cmRF, what = "classes"), file = "cmRF_classes.csv")
cmKNN <-confusionMatrix(knnPred1, testSet$label_location)
print(cmKNN)
as.table(cmKNN)
as.matrix(cmKNN,what="overall")
as.matrix(cmKNN, what = "classes")
write.csv(as.table(cmKNN), file = "cmKNN.csv")
write.csv(as.matrix(cmKNN,what="overall"), file = "cmKNN_overall.csv")
write.csv(as.matrix(cmKNN, what = "classes"), file = "cmKNN_classes.csv")
cmC50 <-confusionMatrix(c50Pred1, testSet$label_location)
print(cmKNN)
as.table(cmC50)
as.matrix(cmC50,what="overall")
as.matrix(cmC50, what = "classes")
write.csv(as.table(cmC50), file = "cmC50.csv")
write.csv(as.matrix(cmC50,what="overall"), file = "cmC50_overall.csv")
write.csv(as.matrix(cmC50, what = "classes"), file = "cmC50_classes.csv")
# use resamples to compare model performance
ModelFitResults <- resamples(list(rf=rfPred1, knn=knnPred1, c50=c50Pred1))
# use resamples to compare model performance
ModelFitResults <- resamples(list(rf=rfPred1, knn=knnPred1, c50=c50Pred1))
validationData <- read.csv("validationData.csv", stringsAsFactors = FALSE)
validationData$TIMESTAMP <- NULL
validationData$USERID <- NULL
validationData$PHONEID <- NULL
validationData$RELATIVEPOSITION <- NULL
validationData$LATITUDE <- NULL
validationData$LONGITUDE <- NULL
head(validationData)
validationDataWCombined = validationData %>% unite("label_location", FLOOR:SPACEID, na.rm = TRUE, remove = FALSE)
summary(validationDataWCombined)
summary(validationDataWCombined$label_location)
validationDataWCombined$BUILDINGID <- NULL
validationDataWCombined$SPACEID <- NULL
validationDataWCombined$FLOOR <- NULL
write.csv(trainingDataWCombined, file = "trainingDataWCombined.csv")
write.csv(validationDataWCombined, file = "validationDataWCombined.csv")
View(validationData)
# make predictions
finalPred <- predict(c50Fit1, validationDataWCombined, predict.all = TRUE)
# make predictions
finalPred <- predict(c50Fit1, validationDataWCombined, predict.all = TRUE)
View(validationDataWCombined)
# make predictions
finalPred <- predict(c50Fit1, validationDataWCombined)
View(trainingDataWCombined)
write.csv(validationDataWCombined, file = "validationDataWCombined.csv")
validationDataWCombined<- read.csv("validationDataWCombined.csv")
View(validationDataWCombined)
# make predictions
finalPred <- predict(c50Fit1, validationDataWCombined)
finalPred
# save model
saveRDS(c50Fit1, "BestPerformingModelC50.RDS")  # Q: What type of object does saveRDS create?
output <- read.csv("validationData.csv", stringsAsFactors = FALSE)
output$Predictions <- finalPred
write.csv(output, file="C3.T3output.csv", row.names = TRUE)
as.matrix(cmKNN,what="overall")
as.matrix(cmC50,what="overall")
as.matrix(cmKNN,what="overall")
as.matrix(cmRF, what = "classes")
as.matrix(cmRF,what="overall")
c50Pred1
c50Fit1
summary(c50Fit1)
write(summary(c50Fit1, file="C50Summary.tx"))
View(c50Fit1)
summary(rfPred1)
rfPred1
write(rfPred1, file = "rfPred1Results.txt")
summary(rfPred1)
summary(rfFit1)
summary(knnFit1)
summary(c50Fit1)
dump(summary(knnFit1), dumpfile.R)
dump(summary(knnFit1), file = "dumpfile.R")
dump(summary(knnFit1), file = "dumpfile.txt")
#FUNCTION to write output to text file
#supply fxn with title of model (in quotes) and model name
writeOutput.F <- function(output.title, modelname) {
sink(file="modeloutputs.txt", append=TRUE) #creates an empty file; if TRUE, it will append to the file
print("##########################", row.names=FALSE)
print(output.title, row.names=FALSE)
print("##########################",  row.names=FALSE)
summary(modelname) #write summary of the model to text file
}
WriteOutput.F("knnFit1", knnFit1)
WriteOutput.F("knnFit1", knnFit1)
writeOutput.F("knnFit1", knnFit1)
writeOutput.F("knnFit1", c50Fit1)
writeOutput.F("rfFit1", rfFit1)
writeOutput.F("knnFit1", knnFit1)
writeOutput.F("c50Fit1", c50Fit1)
closeAllConnections() #close all connections and restore all sink di
writeOutput.F("rfFit1", rfFit1)
closeAllConnections() #close all connections and restore all sink di
writeOutput.F("knnFit1", knnFit1)
writeOutput.F("c50Fit1", c50Fit1)
closeAllConnections() #close all connections and restore all sink di
# print predictions
knnPred1
results <- add_column(testSet, knnPred1)
if(!require(dplyr)){
install.packages("dplyr")
library(dplyr)
}
library(tidyr)
results <- add_column(testSet, knnPred1)
if(!require(caret)){
install.packages("caret")
library(caret)
}
results <- add_column(testSet, knnPred1)
writeOutput.F("rfPred1 Results", rfPred1)
closeAllConnections() #close all connections and restore all sink di
writeOutput.F("knnPred1 Results", knnPred1)
closeAllConnections() #close all connections and restore all sink di
writeOutput.F("C5.0Pred1 Results", C5.0Pred1)
closeAllConnections() #close all connections and restore all sink di
writeOutput.F("C5.0Pred1 Results", C50Pred1)
closeAllConnections() #close all connections and restore all sink di
writeOutput.F("C5.0Pred1 Results", c50Pred1)
closeAllConnections() #close all connections and restore all sink di
write.csv(rfPred1, file = "rfPred1Results.csv", sep = ",")
write.csv(rfPred1, file = "knnPred1Results.csv", sep = ",")
write.csv(rfPred1, file = "c50Pred1Results.csv", sep = ",")
plotData <- c(0.713690352, 0.713115634, 0.469472807, 0.468443225, 0.760575120, 0.760124186) #rfA, rfK, knnA, knnK, c50A, c50K
data <- structure(list(W= c(0.713690352, 0.713115634), X = c(0.469472807, 0.468443225),
Y = c(0.760575120, 0.760124186)), .Names = c("RF", "KNN", "C5.0"), class = "data.frame", row.names = c(NA, -5L))
attach(data)
print(data)
data <- structure(list(W= c(0.713690352, 0.713115634), X = c(0.469472807, 0.468443225),
Y = c(0.760575120, 0.760124186)), .Names = c("RF", "KNN", "C5.0"), class = "data.frame", row.names = c(NA, -3L))
attach(data)
print(data)
data <- structure(list(W= c(0.713690352, 0.713115634), X = c(0.469472807, 0.468443225),
Y = c(0.760575120, 0.760124186)), .Names = c("RF", "KNN", "C5.0"), class = "data.frame", row.names = c(NA, -2L))
attach(data)
print(data)
colours <- c("red", "orange", "blue", "yellow", "green")
barplot(as.matrix(data), main="My Barchart", ylab = "Numbers", cex.lab = 1.5, cex.main = 1.4, beside=TRUE, col=colours)
barplot(as.matrix(data), main="Performance Metrics", ylab = "Values", cex.lab = 1.5, cex.main = 1.4, beside=FALSE, col=colours)
barplot(as.matrix(data), main="Performance Metrics", ylab = "Values", cex.lab = 1.5, cex.main = 1.4, beside=TRUE, col=colours)
colours <- c("green", "blue")
barplot(as.matrix(data), main="Performance Metrics", ylab = "Values", cex.lab = 1.5, cex.main = 1.4, beside=TRUE, col=colours)
legend("topleft", c("rfAccuracy","rfKappa","knnAccuracy","knnKappa","c50Accuracy","c50Kappa"), cex=1.3, bty="n", fill=colours)
legend("topleft", c("rfAccuracy","rfKappa","knnAccuracy","knnKappa","c50Accuracy","c50Kappa"), cex=0.5, bty="n", fill=colours)
legend("topleft", c("rfAccuracy","rfKappa","knnAccuracy","knnKappa","c50Accuracy","c50Kappa"), cex=0.5, bty="n", fill=colours)
barplot(as.matrix(data), main="Performance Metrics", ylab = "Values", cex.lab = 1.5, cex.main = 1.4, beside=TRUE, col=colours)
barplot(as.matrix(data), main="Performance Metrics", ylab = "Values", cex.lab = 1.5, cex.main = 1.0, beside=TRUE, col=colours)
barplot(as.matrix(data), main="Performance Metrics", ylab = "Values", cex.lab = 1.0, cex.main = 1.0, beside=TRUE, col=colours)
legend("topleft", c("rfAccuracy","rfKappa","knnAccuracy","knnKappa","c50Accuracy","c50Kappa"), cex=0.5, bty="n", fill=colours)
legend("bottom", c("rfAccuracy","rfKappa","knnAccuracy","knnKappa","c50Accuracy","c50Kappa"), cex=0.5, bty="n", fill=colours)
legend("top", c("rfAccuracy","rfKappa","knnAccuracy","knnKappa","c50Accuracy","c50Kappa"), cex=0.5, bty="n", fill=colours)
legend("top", c("Accuracy","Kappa"), cex=0.5, bty="n", fill=colours)
legend("top", c("Accuracy","Kappa"), cex=1.0, bty="n", fill=colours)
barplot(as.matrix(data), main="Performance Metrics \n test", ylab = "Values", cex.lab = 1.0, cex.main = 1.0, beside=TRUE, col=colours)
barplot(as.matrix(data), main="Performance Metrics \n Green = Accuracy, Blue = Kappa", ylab = "Values", cex.lab = 1.0, cex.main = 1.0, beside=TRUE, col=colours)
barplot(as.matrix(data), main="Performance Metrics \n Green = Accuracy, Blue = Kappa", ylab = "Values", ylim = c(0.0, 1.0), cex.lab = 1.0, cex.main = 1.0, beside=TRUE, col=colours)
text(bp, 0, round(data, 2),cex=1,pos=3)
bp <- barplot(as.matrix(data), main="Performance Metrics \n Green = Accuracy, Blue = Kappa", ylab = "Values", ylim = c(0.0, 1.0), cex.lab = 1.0, cex.main = 1.0, beside=TRUE, col=colours)
text(bp, 0, round(data, 2),cex=1,pos=3)
text(bp, 0, round(data, 2),cex=.5,pos=3)
text(bp, 0, round(data, 1),cex=.5,pos=3)
bp <- barplot(as.matrix(data), main="Performance Metrics \n Green = Accuracy, Blue = Kappa", ylab = "Values", ylim = c(0.0, 1.0), cex.lab = 1.0, cex.main = 1.0, beside=TRUE, col=colours)
text(bp, 0, round(data, 1),cex=.5,pos=3)
text(bp, 0, round(data, 4),cex=.5,pos=3)
bp <- barplot(as.matrix(data), main="Performance Metrics \n Green = Accuracy, Blue = Kappa", ylab = "Values", ylim = c(0.0, 1.0), cex.lab = 1.0, cex.main = 1.0, beside=TRUE, col=colours)
text(bp, 0, round(data, 4),cex=.5,pos=3)
colours <- c("green", "yellow")
bp <- barplot(as.matrix(data), main="Performance Metrics \n Green = Accuracy, Blue = Kappa", ylab = "Values", ylim = c(0.0, 1.0), cex.lab = 1.0, cex.main = 1.0, beside=TRUE, col=colours)
text(bp, 0, round(data, 4),cex=.5,pos=3)
text(bp, 0, round(data, 4),cex=.5,pos=2)
text(bp, 0, round(data, 4),cex=.5,pos=7)
text(bp, 0, round(data, 4),cex=.5,pos=5)
text(bp, 0, round(data, 4),cex=.5,pos=3)
text(bp, 1, round(data, 4),cex=.5,pos=3)
bp <- barplot(as.matrix(data), main="Performance Metrics \n Green = Accuracy, Blue = Kappa", ylab = "Values", ylim = c(0.0, 1.0), cex.lab = 1.0, cex.main = 1.0, beside=TRUE, col=colours)
text(bp, 1, round(data, 4),cex=.5,pos=3)
text(bp, .5, round(data, 4),cex=.5,pos=3)
bp <- barplot(as.matrix(data), col = c("lightblue", "lavender"), main="Performance Metrics \n Green = Accuracy, Blue = Kappa", ylab = "Values", ylim = c(0.0, 1.0), cex.lab = 1.0, cex.main = 1.0, beside=TRUE, col=colours)
bp <- barplot(as.matrix(data), main="Performance Metrics \n Green = Accuracy, Blue = Kappa", ylab = "Values", ylim = c(0.0, 1.0), cex.lab = 1.0, cex.main = 1.0, beside=TRUE, col=c("lightblue", "lavender"))
text(bp, .5, round(data, 4),cex=.5,pos=3)
data <- structure(list(W= c(0.713690352, 0.713115634), X = c(0.469472807, 0.468443225),
Y = c(0.760575120, 0.760124186)), .Names = c("RF", "KNN", "C5.0"), class = "matrix", row.names = c(NA, -2L))
attach(data)
print(data)
colours <- c("green", "yellow")
bp <- barplot(as.matrix(data), main="Performance Metrics \n Green = Accuracy, Blue = Kappa", ylab = "Values", ylim = c(0.0, 1.0), cex.lab = 1.0, cex.main = 1.0, beside=TRUE, col=c("lightblue", "lavender"))
text(bp, .5, round(data, 4),cex=.5,pos=3)
data <- structure(list(W= c(0.713690352, 0.713115634), X = c(0.469472807, 0.468443225),
Y = c(0.760575120, 0.760124186)), .Names = c("RF", "KNN", "C5.0"), row.names = c(NA, -2L))
attach(data)
print(data)
colours <- c("green", "yellow")
bp <- barplot(as.matrix(data), main="Performance Metrics \n Green = Accuracy, Blue = Kappa", ylab = "Values", ylim = c(0.0, 1.0), cex.lab = 1.0, cex.main = 1.0, beside=TRUE, col=c("lightblue", "lavender"))
bp <- barplot(as.matrix(as.numeric(data)), main="Performance Metrics \n Green = Accuracy, Blue = Kappa", ylab = "Values", ylim = c(0.0, 1.0), cex.lab = 1.0, cex.main = 1.0, beside=TRUE, col=c("lightblue", "lavender"))
data <- structure(list(W= c(0.713690352, 0.713115634), X = c(0.469472807, 0.468443225),
Y = c(0.760575120, 0.760124186)), .Names = c("RF", "KNN", "C5.0"),  class = "data.frame", row.names = c(NA, -2L))
attach(data)
print(data)
colours <- c("green", "yellow")
bp <- barplot(as.matrix(data), main="Performance Metrics \n Green = Accuracy, Blue = Kappa", ylab = "Values", ylim = c(0.0, 1.0), cex.lab = 1.0, cex.main = 1.0, beside=TRUE, col=c("lightblue", "lavender"))
text(bp, .5, round(data, 4),cex=.5,pos=3)
bp <- barplot(as.matrix(data), main="Performance Metrics \n Green = Accuracy, Blue = Kappa", ylab = "Values", ylim = c(0.0, 1.0), cex.lab = 1.0, cex.main = 1.0, beside=TRUE, col=c("lightblue", "lavender"))
View(validationData)
# --- Load Train/Existing data (Dataset 1) --- ############
trainingData <- read.csv("trainingData.csv", stringsAsFactors = FALSE)
validationData <- read.csv("validationData.csv", stringsAsFactors = FALSE)
str(validationData)    #1111 obs. of  529 variables
if(!require(plotly)) {
install.packages("plotly")
library(plotly)
}
x <- c('RF', 'KNN', 'C5.0')
y <- c(0.713690352, 0.469472807, 0.760575120)
y2 <- c(0.713115634,0.468443225,0.760124186)
data <- data.frame(x, y, y2)
p <- data %>%
plot_ly() %>%
add_trace(x = ~x, y = ~y, type = 'bar',
text = y, textposition = 'auto',
marker = list(color = 'rgb(158,202,225)',
line = list(color = 'rgb(8,48,107)', width = 1.5))) %>%
add_trace(x = ~x, y = ~y2, type = 'bar',
text = y2, textposition = 'auto',
marker = list(color = 'rgb(58,200,225)',
line = list(color = 'rgb(8,48,107)', width = 1.5))) %>%
layout(title = "Performance Metrics",
barmode = 'group',
xaxis = list(title = ""),
yaxis = list(title = ""))
p
p <- data %>%
plot_ly() %>%
add_trace(x = ~x, y = ~y, name = "Accuracy", type = 'bar',
text = y, textposition = 'auto',
marker = list(color = 'rgb(158,202,225)',
line = list(color = 'rgb(8,48,107)', width = 1.5))) %>%
add_trace(x = ~x, y = ~y2, type = 'bar',
text = y2, textposition = 'auto',
marker = list(color = 'rgb(58,200,225)',
line = list(color = 'rgb(8,48,107)', width = 1.5))) %>%
layout(title = "Performance Metrics",
barmode = 'group',
xaxis = list(title = ""),
yaxis = list(title = ""))
p
p <- data %>%
plot_ly() %>%
add_trace(x = ~x, y = ~y, name = "Accuracy", type = 'bar',
text = y, textposition = 'auto',
marker = list(color = 'rgb(158,202,225)',
line = list(color = 'rgb(8,48,107)', width = 1.5))) %>%
add_trace(x = ~x, y = ~y2, name = "Kappa", type = 'bar',
text = y2, textposition = 'auto',
marker = list(color = 'rgb(58,200,225)',
line = list(color = 'rgb(8,48,107)', width = 1.5))) %>%
layout(title = "Performance Metrics",
barmode = 'group',
xaxis = list(title = ""),
yaxis = list(title = ""))
p
